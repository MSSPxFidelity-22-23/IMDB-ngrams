---
title: "Draft Fidelity"
author: "Jiun Lee"
date: "2022-10-15"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
imdb <- read.csv("/Users/jiunlee/MSSP22/MA675/IMDB/IMDB Dataset.csv")
imdb <- imdb %>% select(-sentiment)
# avector <- as.vector(imdb['review']) #sublist
# class(avector) 
# 
# avector <- imdb[['review']] #atomic column
# class(avector)

text <- imdb[,1] #vector
text_df <- tibble(line = 1:50000, text = text)
```


#tokenizing
```{r}
library(tidytext)
tidy <- text_df %>%
  unnest_tokens(word, text, token="words") %>%
  anti_join(stop_words)

common <- tidy %>%
  count(word, sort = TRUE) 
#most common: br>movie>film>time>...

library(ggplot2)

tidy %>%
  count(word, sort = TRUE) %>%
  filter(n > 600) %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(n, word)) +
  geom_col() +
  labs(y = NULL)


library(tidyr)

frequency <- tidy %>%
  mutate(word = str_replace(word, "br", NA_character_)) %>%
  drop_na() %>%
  count(line,word) %>%
  group_by(line) %>%
  arrange(desc(n)) %>%
  slice(1:7)
  
#tokenizing by ngrams
library(tokenizers)
#n=3
tft_token_ngram3 <- tokenize_ngrams(x = text,
                                   lowercase = TRUE,
                                   n = 3L,
                                   n_min = 3L,
                                   stopwords = character(),
                                   ngram_delim = " ",
                                   simplify = FALSE)
tft_token_ngram3[[1]]

#n=2
tft_token_ngram2 <- tokenize_ngrams(x = text,
                                  lowercase = TRUE,
                                   n = 2L,
                                   n_min = 2L,
                                   stopwords = character(),
                                   ngram_delim = " ",
                                   simplify = FALSE)
tft_token_ngram2[[1]]

#mixing n=1,n=2
tft_token_ngram12 <- tokenize_ngrams(x = text,
                                  lowercase = TRUE,
                                   n = 2L,
                                   n_min = 1L,
                                   stopwords = character(),
                                   ngram_delim = " ",
                                   simplify = FALSE)
tft_token_ngram12[[1]]
#no words coming after adjective

#checking if numbers are meaningful

#frequency of ngrams


```


#use regex to remove line breaks <…> ex)<br /><br />   
```{r}
# replaced = gsub(
#   pattern = '<.*>',   #pattern: regex
#   replacement = "",   #remove
#   x = imdb,
#   ignore.case = TRUE,
#   perl = TRUE
# )
# 
# imdb2 <- as.data.frame(replaced)
# 
# 

```