---
title: "Draft Fidelity 2"
author: "Jiun Lee"
date: "2022-10-15"
output: html_document
---

```{r setup, include=FALSE}
library(knitr)
library(tidyverse)
library(readxl)
library(tokenizers)
library(tidytext)
library(DescTools)
library(stringr)
library(tidyr)
library(fitdistrplus)
library(MASS)
library(Hmisc)
opts_chunk$set(echo = TRUE)
```

read the IMDB dataset

```{r}
imdb <- read_csv   ("IMDB Dataset.csv", 
                    col_names = TRUE,
                    show_col_types = FALSE)

## remove sentiment column
imdb <- imdb[,-2]


## sample down
n_sample <- 1000
text_df <- imdb %>% slice_sample(n = n_sample, replace = FALSE)

```


#tokenizing by bigram

```{r}
library(tokenizers)
library(tidytext)
library(DescTools)

## create bigrams
token_bigram <- text_df %>% 
  unnest_tokens(bigram, 
                review, 
                token = "ngrams", 
                n = 2, 
                to_lower=TRUE) %>% 
  filter(!is.na(bigram))

## create a stop word vector
stop <-  unlist(stop_words[,1])

## drop the attribute
stop <- StripAttr(stop)

## add to the stop list
stop <- c(stop, "br")

## split the bigram list into two columns
check <-  token_bigram %>% separate(bigram, 
                                    sep= " ", 
                                    c("w1", "w2"))

## check both words individually agains stop word lists
a <- check$w1 %in% stop
b <- check$w2 %in% stop

## the bigram is included only if neither 
## of the single words is a stop word

remove <- (a|b)

## to make it easier to see create a data frame
d <- cbind(token_bigram, a, b, remove)

## create an index of bigram
f <- which(d$remove == FALSE)

## use the index to make a list of bigrams
g <- d$bigram[f]


```

#1 distribution of the length
```{r}
set.seed(100)
nwords <- function(string, pseudo=F){
  ifelse( pseudo, 
          pattern <- "\\S+", 
          pattern <- "[[:alpha:]]+" 
        )
  str_count(string, pattern)
}
text_df$length <- nwords(text_df$review, pseudo = F)

ggplot(data = text_df)+
  geom_histogram(mapping=aes(x = length, y = ..density..),binwidth=5)+
  xlab("length of each review") +
  ggtitle("Distribution of review lengths")



length_dist <- fitdist(text_df$length, "pois") |>print()
qqcomp(fitdist(text_df$length, "pois"))
cdfcomp(fitdist(text_df$length, "pois"))


```


#2 punctuation frenquincy
```{r}
text_df$comma <- str_count(text_df$review,'\\,' )
text_df$dot <- str_count(text_df$review,'\\.')
text_df$question <- str_count(text_df$review, '\\?')
text_df$exclamation <- str_count(text_df$review,'\\!')
plot_data<- text_df[,c(-1)]

ggplot(data = text_df)+
  geom_histogram(mapping=aes(x = comma, y = ..count..),binwidth=.5)
  
hist.data.frame(plot_data)
# punc = melt(text_df[,1:2])
# ggplot(data = punc) +
#   geom_histogram(aes(x = value, y=(..count..)/sum(..count..), fill=variable), 
#                  alpha=0.3, binwidth=2, position="identity")
# # 
# # library(reshape2)
# # iris2 = melt(text_df[,c()])
# # ggplot(data = iris2) +
# #   geom_histogram(aes(x = value, y=(..count..)/sum(..count..), fill=variable), 
# #                  alpha=0.3, binwidth=2, position="identity")
```



```{r}
(review_separated <- token_bigram %>%  
  separate(bigram, into = c("word1", "word2"), sep = " ")
)
review_united <- review_separated %>%
  filter(!word1 %in% c('br'),
         !word2 %in% c('br')) %>%
  unite(bigram, c(word1, word2), sep = " ")

# freq_bigram <- token_bigram %>% count(bigram,sort = TRUE)

total_bigram <- review_united %>% 
  group_by(review) %>% 
  summarize(total = sum(n))

review_bigram <- left_join(review_united, total_bigram)

rm(token_bigram, review_separated, review_united, total_bigram)

#Zipfâ€™s law states that the frequency that a word appears is inversely proportional to its rank.
# freq_by_rank_bi <- review_bigram %>% 
#   group_by(review) %>% 
#   mutate(rank = row_number(), 
#          `term frequency` = n/total) %>%
#   ungroup()
# 
# #ggplot
# freq_by_rank_bi %>% 
#   ggplot(aes(rank, `term frequency`, color = review)) + 
#   geom_line(size = 1.1, alpha = 0.8, show.legend = FALSE) + 
#   scale_x_log10() +
#   scale_y_log10()
```

#tf-idf
```{r}
review_tf_idf_bi <- review_bigram %>%
  bind_tf_idf(bigram, review, n)

#look at terms with high tf-idf in reviews.

review_tf_idf_bi <- review_tf_idf_bi %>%
  select(-total) %>%
  arrange(desc(tf_idf))

#too many 'br br' -> let's remove 'br br'


# #resume tf-idf
# review_tf_idf_bi2 <- review_united %>%
#   bind_tf_idf(bigram, review, n)
# 
# review_tf_idf_bi2 
# 
# #look at terms with high tf-idf in reviews.
# review_tf_idf_bi2 %>%
#   arrange(desc(tf_idf))

library(ggplot2)
library(forcats)


```


